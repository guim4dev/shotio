{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65177769-d515-4c72-94a8-097233861d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from datetime import timedelta as td\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3a01e2-fdd6-43dd-8480-28267bb3faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_RATE = 44100\n",
    "AUDIO_VOLUME_THRESHOLD = 0.2\n",
    "NOISE_REDUCTION_ENABLED = False\n",
    "MINIMUM_FREQUENCY = 20\n",
    "MAXIMUM_FREQUENCY = AUDIO_RATE // 2\n",
    "NUMBER_OF_MELS = 128\n",
    "NUMBER_OF_FFTS = NUMBER_OF_MELS * 20\n",
    "noise_sample_captured = False\n",
    "noise_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77f9e00-2038-43f3-b7a4-a2a2955bcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9793193-7539-4379-a3b9-f3f64b01581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_to_db(S, ref=1.0, amin=1e-10, top_db=80.0):\n",
    "    S = np.asarray(S)\n",
    "    if amin <= 0:\n",
    "        print(\"Error\")\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        print(\"Warning: power_to_db was called on complex input so phase information will be discarded.\")\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "    if callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            print(\"ParameterError: top_db must be non-negative\")\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "def convert_audio_to_spectrogram(data):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=data, sr=AUDIO_RATE,\n",
    "                                                 hop_length=HOP_LENGTH,\n",
    "                                                 fmin=MINIMUM_FREQUENCY,\n",
    "                                                 fmax=MAXIMUM_FREQUENCY,\n",
    "                                                 n_mels=NUMBER_OF_MELS,\n",
    "                                                 n_fft=NUMBER_OF_FFTS)\n",
    "    spectrogram = power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591f4ad5-1736-4a7f-b317-6612983cbff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft(y, n_fft, hop_length, win_length):\n",
    "    return librosa.stft(y = y, n_fft = n_fft, hop_length = hop_length, win_length = win_length)\n",
    "\n",
    "\n",
    "def _istft(y, hop_length, win_length):\n",
    "    return librosa.istft(y, hop_length, win_length)\n",
    "\n",
    "\n",
    "def _amp_to_db(x):\n",
    "    return librosa.core.logamplitude(x, ref_power = 1.0, amin = 1e-20, top_db = 80.0)  # Librosa 0.4.2 functionality\n",
    "\n",
    "\n",
    "def _db_to_amp(x):\n",
    "    return librosa.core.perceptual_weighting(x, frequencies = 1.0)  # Librosa 0.4.2 functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483e791f-6c85-4af2-ab72-53d494632d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(audio_clip,\n",
    "                noise_clip,\n",
    "                n_grad_freq = 2,\n",
    "                n_grad_time = 4,\n",
    "                n_fft = 2048,\n",
    "                win_length = 2048,\n",
    "                hop_length = 512,\n",
    "                n_std_thresh = 1.5,\n",
    "                prop_decrease = 1.0,\n",
    "                verbose = False):\n",
    "    \n",
    "    \"\"\" Removes noise from audio based upon a clip containing only noise\n",
    "\n",
    "    Args:\n",
    "        audio_clip (array): The first parameter.\n",
    "        noise_clip (array): The second parameter.\n",
    "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
    "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
    "        n_fft (int): number audio of frames between STFT columns.\n",
    "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
    "        hop_length (int):number audio of frames between STFT columns.\n",
    "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
    "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
    "        verbose: Whether to display time statistics for the noise reduction process\n",
    "\n",
    "    Returns:\n",
    "        array: The recovered signal with noise subtracted\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the noise sample\n",
    "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
    "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # Converts the sample units to dB\n",
    "    \n",
    "    # Calculates statistics over the noise sample\n",
    "    mean_freq_noise = np.mean(noise_stft_db, axis = 1)\n",
    "    std_freq_noise = np.std(noise_stft_db, axis = 1)\n",
    "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on noise:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the signal sample\n",
    "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
    "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on signal:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Calculates value to which to mask dB\n",
    "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Noise Threshold & Mask Gain in dB: \", noise_thresh, mask_gain_dB)\n",
    "    \n",
    "    # Creates a smoothing filter for the mask in time and frequency\n",
    "    smoothing_filter = np.outer(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_freq + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_freq + 2),\n",
    "            ]\n",
    "        )[1:-1],\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_time + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_time + 2),\n",
    "            ]\n",
    "        )[1:-1]\n",
    "    )\n",
    "    \n",
    "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
    "    \n",
    "    # Calculates the threshold for each frequency/time bin\n",
    "    db_thresh = np.repeat(np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
    "                          np.shape(sig_stft_db)[1],\n",
    "                          axis = 0).T\n",
    "    \n",
    "    # Masks segment if the signal is above the threshold\n",
    "    sig_mask = sig_stft_db < db_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Masking:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Convolves the mask with a smoothing filter\n",
    "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
    "    sig_mask = sig_mask * prop_decrease\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask convolution:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Masks the signal\n",
    "    sig_stft_db_masked = (sig_stft_db * (1 - sig_mask)\n",
    "                          + np.ones(np.shape(mask_gain_dB))\n",
    "                          * mask_gain_dB * sig_mask)  # Masks real\n",
    "    \n",
    "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
    "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (1j * sig_imag_masked)\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask application:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Recovers the signal\n",
    "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
    "    recovered_spec = _amp_to_db(\n",
    "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
    "    )\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Signal recovery:\", td(seconds = time.time() - start))\n",
    "        \n",
    "    # Returns noise-reduced audio sample\n",
    "    return recovered_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4789f210-89b1-4b98-9d23-6b432d433120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 64, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 64, 16)       272       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 64, 16)      64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 32, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        8224      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 32)        16416     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        32832     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 64)        65600     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,170\n",
      "Trainable params: 272,242\n",
      "Non-trainable params: 928\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"../model/model.h5\", custom_objects = {\n",
    "        \"auc\": auc\n",
    "    })\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b068d9e-6e2b-4924-b8e5-8deee1a5c09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: (75805,)\n",
      "Sample rate 22050\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data, rate = librosa.load(\"../sounds/gunshots/audio_guima_1.wav\")\n",
    "# data, rate = librosa.load(\"../sounds/others/audio_guima_2.wav\")\n",
    "\n",
    "print(\"Sample shape:\", data.shape)\n",
    "print(\"Sample rate\", rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a90b0bc-7ca5-4a04-8c24-40c3e199599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_frequency_value = np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a2f435d-7f5e-4f4f-a54a-8f5f1dcdbf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum frequency value of a given sample before processing: 0.28043047\n"
     ]
    }
   ],
   "source": [
    " if maximum_frequency_value >= AUDIO_VOLUME_THRESHOLD:\n",
    "        \n",
    "    # Displays the current sample's maximum frequency value\n",
    "    print(\"The maximum frequency value of a given sample before processing: \" + str(maximum_frequency_value))\n",
    "\n",
    "    # Post-processes the microphone data\n",
    "    # modified_microphone_data = librosa.resample(y = microphone_data, orig_sr = AUDIO_RATE, target_sr = 41000)\n",
    "    modified_data = data\n",
    "    if NOISE_REDUCTION_ENABLED and noise_sample_captured:\n",
    "        # Acts as a substitute for normalization\n",
    "        modified_data = remove_noise(audio_clip = modified_data, noise_clip = noise_sample)\n",
    "        number_of_missing_hertz = 44100 - len(modified_data)\n",
    "        modified_data = np.array(modified_data.tolist() + [0 for i in range(number_of_missing_hertz)], dtype = \"float32\")\n",
    "    modified_data = modified_data[:44100]\n",
    "    \n",
    "    HOP_LENGTH = 345 * 2\n",
    "    processed_data = convert_audio_to_spectrogram(data = modified_data)\n",
    "    processed_data = processed_data.reshape(1, 128, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a90b910e-6a91-418a-a26b-de1f7279fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(processed_data).astype(float).ravel()\n",
    "result = bool(np.argmax(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49417fc6-487f-4c92-8a82-751753cc2bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': True, 'probability': 0.9999115467071533}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = {\"result\": result,\n",
    "            \"probability\": y[1]}\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
